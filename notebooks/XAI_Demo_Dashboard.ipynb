{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636ba239",
   "metadata": {},
   "source": [
    "\n",
    "# üß™ Time-Series Forecasting Demo ‚Äî Dashboard Style\n",
    "\n",
    "This notebook lets you:\n",
    "1. üîº Upload **or** automatically load the dataset  \n",
    "2. üìå Select a **model** via dropdown  \n",
    "3. üìä Re-run **forecasting**  \n",
    "4. üìà See results (**Actual vs Predicted**, **Error plot**, **Model metrics**)  \n",
    "5. üîç Add **Explainable AI (SHAP + LIME)**  \n",
    "6. üèÜ Final output summary with model & top features  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19396e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup & Imports ===\n",
    "import sys, io, os, json, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure our modular package is importable\n",
    "sys.path.append('/mnt/data')\n",
    "sys.path.append('/mnt/data/xai_pipeline')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Pipeline modules\n",
    "from xai_pipeline.data_loader import load_covid_aggregated\n",
    "from xai_pipeline.preprocessing import scale_features, create_sequences, train_test_sequence_split\n",
    "from xai_pipeline.metrics import regression_metrics\n",
    "from xai_pipeline.plots import plot_predictions\n",
    "from xai_pipeline.shap import explain_model as shap_explain\n",
    "\n",
    "# Models\n",
    "from xai_pipeline.models.lstm import build_lstm\n",
    "from xai_pipeline.models.bilstm import build_bilstm\n",
    "from xai_pipeline.models.cnn import build_cnn\n",
    "from xai_pipeline.models.hybrid_cnn_lstm import build_hybrid_cnn_lstm\n",
    "from xai_pipeline.models.rnn import build_rnn\n",
    "from xai_pipeline.models.mlp import build_mlp\n",
    "from xai_pipeline.models.hybrid_mlp_cnn_lstm import build_hybrid_mlp_cnn_lstm\n",
    "from xai_pipeline.models.hybrid_cnn_bilstm import build_hybrid_cnn_bilstm\n",
    "from xai_pipeline.models.hybrid_cnn_dense import build_hybrid_cnn_dense\n",
    "\n",
    "# TF callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Optional: LIME (graceful fallback if not installed)\n",
    "try:\n",
    "    from xai_pipeline.lime import explain_instance as lime_explain\n",
    "    _lime_ok = True\n",
    "except Exception as _e:\n",
    "    _lime_ok = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce83274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === UI Widgets ===\n",
    "\n",
    "# 1. Data source\n",
    "uploader = widgets.FileUpload(accept='.csv', multiple=False, description='Upload CSV')\n",
    "auto_load_btn = widgets.Button(description='Use Sample COVID CSV', tooltip='Auto-load cached Kaggle COVID dataset (if present)')\n",
    "\n",
    "# 2. Model selection\n",
    "model_options = {\n",
    "    \"LSTM\": \"lstm\",\n",
    "    \"BiLSTM\": \"bilstm\",\n",
    "    \"CNN (1D)\": \"cnn\",\n",
    "    \"Hybrid: CNN + LSTM\": \"hybrid_cnn_lstm\",\n",
    "    \"RNN (SimpleRNN)\": \"rnn\",\n",
    "    \"MLP (Flattened T*F)\": \"mlp\",\n",
    "    \"Hybrid: Conv -> LSTM -> MLP\": \"hybrid_mlp_cnn_lstm\",\n",
    "    \"Hybrid: Conv -> BiLSTM\": \"hybrid_cnn_bilstm\",\n",
    "    \"Hybrid: CNN + Dense (baseline)\": \"hybrid_cnn_dense\"\n",
    "}\n",
    "model_dd = widgets.Dropdown(options=list(model_options.keys()), value=\"LSTM\", description='Model')\n",
    "\n",
    "# Controls\n",
    "time_steps = widgets.IntSlider(value=14, min=3, max=60, step=1, description='Time steps')\n",
    "epochs = widgets.IntSlider(value=30, min=5, max=200, step=5, description='Epochs')\n",
    "batch = widgets.IntSlider(value=32, min=8, max=256, step=8, description='Batch')\n",
    "run_btn = widgets.Button(description='Run Forecast', button_style='success')\n",
    "explain_btn = widgets.Button(description='Explain (SHAP + LIME)', button_style='info')\n",
    "out = widgets.Output()\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>1) Data</h3>\"),\n",
    "    widgets.HBox([uploader, auto_load_btn]),\n",
    "    widgets.HTML(\"<h3>2) Model</h3>\"),\n",
    "    model_dd,\n",
    "    widgets.HTML(\"<h3>3) Train Settings</h3>\"),\n",
    "    widgets.HBox([time_steps, epochs, batch]),\n",
    "    widgets.HBox([run_btn, explain_btn]),\n",
    "])\n",
    "display(controls, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Helpers ===\n",
    "\n",
    "def _read_uploaded_csv(uploader):\n",
    "    if len(uploader.value) == 0:\n",
    "        return None\n",
    "    key = list(uploader.value.keys())[0]\n",
    "    content = uploader.value[key]['content']\n",
    "    return pd.read_csv(io.BytesIO(content))\n",
    "\n",
    "def _auto_sample_csv_df():\n",
    "    # Default path used in your notebook\n",
    "    path = \"/root/.cache/kagglehub/datasets/sudalairajkumar/novel-corona-virus-2019-dataset/versions/151/covid_19_data.csv\"\n",
    "    if os.path.exists(path):\n",
    "        return pd.read_csv(path)\n",
    "    return None\n",
    "\n",
    "def _prepare_aggregated_df(df):\n",
    "    # Harmonize to required columns\n",
    "    date_col = None\n",
    "    for c in [\"ObservationDate\", \"Date\", \"date\"]:\n",
    "        if c in df.columns:\n",
    "            date_col = c\n",
    "            break\n",
    "    if date_col is None:\n",
    "        raise ValueError(\"No date-like column found. Expected 'ObservationDate', 'Date', or 'date'.\")\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    pick = lambda names: next((c for c in names if c in df.columns), None)\n",
    "    cC = pick([\"Confirmed\",\"confirmed\"]); cD = pick([\"Deaths\",\"deaths\"]); cR = pick([\"Recovered\",\"recovered\"])\n",
    "    if not all([cC, cD, cR]):\n",
    "        raise ValueError(\"Dataset must include Confirmed/Deaths/Recovered columns.\")\n",
    "    grouped = (df.groupby(df[date_col].dt.date)[[cC, cD, cR]].sum()\n",
    "                 .reset_index().rename(columns={cC:\"Confirmed\", cD:\"Deaths\", cR:\"Recovered\", date_col:\"ObservationDate\"}))\n",
    "    grouped[\"ObservationDate\"] = pd.to_datetime(grouped[\"ObservationDate\"])\n",
    "    grouped[\"Active\"] = grouped[\"Confirmed\"] - grouped[\"Deaths\"] - grouped[\"Recovered\"]\n",
    "    grouped = grouped.sort_values(\"ObservationDate\").reset_index(drop=True)\n",
    "    return grouped\n",
    "\n",
    "def _build_model(kind, input_shape, X_seq=None):\n",
    "    # kind is the value from model_options map\n",
    "    if kind == \"lstm\":\n",
    "        return build_lstm(input_shape)\n",
    "    if kind == \"bilstm\":\n",
    "        return build_bilstm(input_shape)\n",
    "    if kind == \"cnn\":\n",
    "        return build_cnn(input_shape)\n",
    "    if kind == \"hybrid_cnn_lstm\":\n",
    "        return build_hybrid_cnn_lstm(input_shape)\n",
    "    if kind == \"rnn\":\n",
    "        return build_rnn(input_shape)\n",
    "    if kind == \"hybrid_mlp_cnn_lstm\":\n",
    "        return build_hybrid_mlp_cnn_lstm(input_shape)\n",
    "    if kind == \"hybrid_cnn_bilstm\":\n",
    "        return build_hybrid_cnn_bilstm(input_shape)\n",
    "    if kind == \"hybrid_cnn_dense\":\n",
    "        return build_hybrid_cnn_dense(input_shape)\n",
    "    if kind == \"mlp\":\n",
    "        # For MLP we need flattened dim\n",
    "        assert X_seq is not None, \"X_seq is required for MLP to determine input dim.\"\n",
    "        input_dim = X_seq.shape[1] * X_seq.shape[2]\n",
    "        return build_mlp(input_dim=input_dim)\n",
    "    raise ValueError(f\"Unknown model kind: {kind}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# State to carry across buttons\n",
    "STATE = dict(\n",
    "    df=None,\n",
    "    X_seq=None, y_seq=None,\n",
    "    X_train=None, X_test=None, y_train=None, y_test=None,\n",
    "    model=None, model_name=None,\n",
    "    y_pred=None,\n",
    "    features=['Confirmed','Deaths','Recovered','Active'],\n",
    "    tsteps=14\n",
    ")\n",
    "\n",
    "def _load_data():\n",
    "    if len(uploader.value):\n",
    "        df_raw = _read_uploaded_csv(uploader)\n",
    "    else:\n",
    "        df_raw = _auto_sample_csv_df()\n",
    "        if df_raw is None:\n",
    "            raise RuntimeError(\"No dataset uploaded and sample path not found.\")\n",
    "    df = _prepare_aggregated_df(df_raw)\n",
    "    return df\n",
    "\n",
    "def _train_and_forecast():\n",
    "    df = _load_data()\n",
    "    STATE['df'] = df\n",
    "    features = STATE['features']\n",
    "    tsteps = time_steps.value\n",
    "    \n",
    "    X_scaled, scaler = scale_features(df, features, scaler_type='minmax')\n",
    "    y = df['Confirmed'].values\n",
    "    X_seq, y_seq = create_sequences(X_scaled, y, time_steps=tsteps)\n",
    "    X_train, X_test, y_train, y_test = train_test_sequence_split(X_seq, y_seq, test_size=0.2)\n",
    "    \n",
    "    model_key = model_options[model_dd.value]\n",
    "    model = _build_model(model_key, X_train.shape[1:], X_seq=X_seq)\n",
    "    callbacks = [EarlyStopping(patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)]\n",
    "    model.fit(X_train, y_train, validation_split=0.1, epochs=epochs.value, batch_size=batch.value, verbose=0, callbacks=callbacks)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    STATE.update(dict(\n",
    "        X_seq=X_seq, y_seq=y_seq,\n",
    "        X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test,\n",
    "        model=model, model_name=model_dd.value, y_pred=y_pred, tsteps=tsteps\n",
    "    ))\n",
    "\n",
    "def _make_plots_and_metrics():\n",
    "    y_true = STATE['y_test'].reshape(-1)\n",
    "    y_pred = STATE['y_pred'].reshape(-1)\n",
    "    # 1) Actual vs Predicted\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(y_true, label='Actual')\n",
    "    plt.plot(y_pred, label='Predicted')\n",
    "    plt.title(f\"Actual vs Predicted ‚Äî {STATE['model_name']}\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2) Error plot\n",
    "    err = y_true - y_pred\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(err, label='Error')\n",
    "    plt.title(\"Prediction Error\")\n",
    "    plt.xlabel(\"Samples\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3) Metrics\n",
    "    mets = regression_metrics(y_true, y_pred)\n",
    "    # Add MAPE\n",
    "    mape = float(np.mean(np.abs((y_true - y_pred) / np.maximum(1e-8, y_true))) * 100.0)\n",
    "    mets['mape'] = mape\n",
    "    dfm = pd.DataFrame([mets])\n",
    "    display(Markdown(\"### Model Metrics\"))\n",
    "    display(dfm)\n",
    "    return mets\n",
    "\n",
    "def _explain_models():\n",
    "    model = STATE['model']\n",
    "    X = STATE['X_test']\n",
    "    features = STATE['features']\n",
    "    # SHAP summary (auto-handles sequences via our helper)\n",
    "    shap_explain(model, X, feature_names=features, title=f\"SHAP Summary ‚Äî {STATE['model_name']}\")\n",
    "    \n",
    "    # Try LIME on a single instance\n",
    "    if _lime_ok:\n",
    "        try:\n",
    "            exp = lime_explain(model, X, feature_names=None, class_names=None, num_features=10, sample_index=0)\n",
    "            display(Markdown(\"### LIME Explanation (sample index 0)\"))\n",
    "            display(exp.as_list())\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"**LIME warning:** {str(e)}\"))\n",
    "    else:\n",
    "        display(Markdown(\"**LIME not available.** Install with `pip install lime` to enable tabular explanations.\"))\n",
    "\n",
    "def _final_summary(mets, top_pos, top_neg):\n",
    "    name = STATE['model_name']\n",
    "    lines = [\n",
    "        f\"‚úî **Model:** {name}\",\n",
    "        f\"‚úî **RMSE:** {mets['rmse']:.4f}\",\n",
    "        f\"‚úî **MAE:** {mets['mae']:.4f}\",\n",
    "        f\"‚úî **MAPE:** {mets['mape']:.2f}%\",\n",
    "        f\"‚úî **Top positive features (SHAP):** {', '.join(f'{k} ({v:+.3f})' for k,v in top_pos)}\",\n",
    "        f\"‚úî **Top negative features (SHAP):** {', '.join(f'{k} ({v:+.3f})' for k,v in top_neg)}\",\n",
    "    ]\n",
    "    display(Markdown(\"## üèÜ Final Output\"))\n",
    "    display(Markdown(\"<br>\".join(lines)))\n",
    "\n",
    "def _compute_shap_top_features():\n",
    "    # Compute average shap values per feature (using our flattening in shap_explain).\n",
    "    # We'll re-run a minimal explainer locally to fetch raw values\n",
    "    import shap\n",
    "    X = STATE['X_test']\n",
    "    model = STATE['model']\n",
    "    features = STATE['features']\n",
    "    \n",
    "    # Flatten to match our explain function behavior\n",
    "    if X.ndim == 3:\n",
    "        n,t,f = X.shape\n",
    "        X_flat = X.reshape(n, t*f)\n",
    "        feat_names = [f\"{name}_t-{ti}\" for ti in range(t-1, -1, -1) for name in features]\n",
    "    else:\n",
    "        X_flat = X\n",
    "        feat_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "    \n",
    "    def model_wrap(x):\n",
    "        if X.ndim == 3:\n",
    "            x = x.reshape(-1, t, f)\n",
    "        return model.predict(x)\n",
    "    \n",
    "    bg = X_flat[: min(100, len(X_flat))]\n",
    "    explainer = shap.Explainer(model_wrap, bg)\n",
    "    sh = explainer(X_flat[: min(200, len(X_flat))])\n",
    "    # Mean SHAP over samples\n",
    "    mean_vals = np.array(sh.values).mean(axis=0)\n",
    "    # Top positive / negative\n",
    "    order_pos = np.argsort(-mean_vals)[:5]\n",
    "    order_neg = np.argsort(mean_vals)[:5]\n",
    "    top_pos = [(feat_names[i], float(mean_vals[i])) for i in order_pos]\n",
    "    top_neg = [(feat_names[i], float(mean_vals[i])) for i in order_neg]\n",
    "    return top_pos, top_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Button Callbacks ===\n",
    "\n",
    "def on_auto_load_clicked(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            df_raw = _auto_sample_csv_df()\n",
    "            if df_raw is None:\n",
    "                display(Markdown(\"**Sample CSV not found. Please upload a CSV.**\"))\n",
    "            else:\n",
    "                display(Markdown(\"**Loaded sample COVID dataset.**\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"**Error:** {e}\"))\n",
    "\n",
    "def on_run_clicked(b):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        try:\n",
    "            _train_and_forecast()\n",
    "            mets = _make_plots_and_metrics()\n",
    "            STATE['mets'] = mets\n",
    "            display(Markdown(\"> ‚úÖ Training & forecasting complete.\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"**Error:** {e}\"))\n",
    "\n",
    "def on_explain_clicked(b):\n",
    "    with out:\n",
    "        try:\n",
    "            _explain_models()\n",
    "            # Compute top +/- for final output\n",
    "            top_pos, top_neg = _compute_shap_top_features()\n",
    "            STATE['top_pos'] = top_pos\n",
    "            STATE['top_neg'] = top_neg\n",
    "            display(Markdown(\"> üîç Explainability complete.\"))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"**Explain Error:** {e}\"))\n",
    "\n",
    "auto_load_btn.on_click(on_auto_load_clicked)\n",
    "run_btn.on_click(on_run_clicked)\n",
    "explain_btn.on_click(on_explain_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c62131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 6) Final Output Cell ===\n",
    "if 'mets' in STATE and 'top_pos' in STATE and 'top_neg' in STATE:\n",
    "    _final_summary(STATE['mets'], STATE['top_pos'], STATE['top_neg'])\n",
    "else:\n",
    "    display(Markdown(\"Run **Forecast** and then **Explain** to populate the final summary here.\"))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
